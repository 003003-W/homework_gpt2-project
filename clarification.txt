原始数据集：input.txt
添加 convert_to_json.py，转换txt为input.json
运行 clr_ctrl.py，得到 train.json，但内部并非仅含一整行文字
命令行运行 jq -c '[([.data[].text] | join(""))]' train.json > out.json，得到 out.json （65MB）用于训练模型
由于数据集过大，调整batch_size=40，stride=1024以减小steps，并增加GPU个数（夜间运行，并未影响他人工作），初次训练：
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 && python train.py --device 0,1,2,3,4,5,6,7 --batch_size 40 --stride 1024 --model_config config/model_config_small.json --tokenized_data_path data/tokenized/  --tokenizer_path cache/vocab_small.txt --raw_data_path data/out.json --epochs 20 --log_step 200 --output_dir model/ --num_pieces 100 --raw
第4轮结束后，训练中断，继续训练：
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 && python train.py --device 0,1,2,3,4,5,6,7 --batch_size 40 --stride 1024 --model_config config/model_config_small.json --tokenized_data_path data/tokenized/ --tokenizer_path cache/vocab_small.txt --raw_data_path data/out.json --epochs 16 --log_step 200 --output_dir ./model/model_resume --num_pieces 100 --pretrained_model model/model_epoch4
训练20轮，结果写入./mnt